package taskengine

import (
	"fmt"
	"regexp"
	"sort"
	"strings"

	"gopkg.in/yaml.v3"
)

var (
	dns1035Re   = regexp.MustCompile(`[^a-z0-9-]+`)
	dns1035Trim = regexp.MustCompile(`^-+|-+$`)
)

func sanitizeDNS1035Label(value string) string {
	value = strings.ToLower(strings.TrimSpace(value))
	value = dns1035Re.ReplaceAllString(value, "-")
	value = dns1035Trim.ReplaceAllString(value, "")

	if value == "" {
		return "n"
	}

	// Must start with a letter.
	if value[0] < 'a' || value[0] > 'z' {
		value = "n-" + value
	}

	// Must end with alphanumeric.
	for len(value) > 0 {
		last := value[len(value)-1]
		if (last >= 'a' && last <= 'z') || (last >= '0' && last <= '9') {
			break
		}
		value = strings.TrimRight(value, "-")
	}

	if value == "" {
		return "n"
	}

	if len(value) > 63 {
		value = value[:63]
		for len(value) > 0 {
			last := value[len(value)-1]
			if (last >= 'a' && last <= 'z') || (last >= '0' && last <= '9') {
				break
			}
			value = strings.TrimRight(value, "-")
		}
	}

	if value == "" {
		return "n"
	}

	return value
}

// sanitizeContainerlabYAMLForClabernetes ensures that node names are valid Kubernetes DNS-1035 labels
// so that clabernetes can safely derive Service/Deployment names from them.
//
// It returns the rewritten containerlab YAML and an old->new node name mapping.
func sanitizeContainerlabYAMLForClabernetes(containerlabYAML string) (string, map[string]string, error) {
	containerlabYAML = strings.TrimSpace(containerlabYAML)
	if containerlabYAML == "" {
		return "", nil, nil
	}

	var doc map[string]any
	if err := yaml.Unmarshal([]byte(containerlabYAML), &doc); err != nil {
		return "", nil, fmt.Errorf("failed to parse containerlab yaml: %w", err)
	}
	if doc == nil {
		return containerlabYAML, nil, nil
	}

	// containerlab YAMLs generated by upstream tooling sometimes include `runtime: docker`.
	// In clabernetes native mode, the runtime is Kubernetes/containerd and this field is
	// ignored. Removing it avoids confusion ("are we using Docker-in-Docker?") while
	// keeping the topology semantically identical.
	if _, ok := doc["runtime"]; ok {
		delete(doc, "runtime")
	}

	topology, ok := doc["topology"].(map[string]any)
	if !ok || topology == nil {
		return containerlabYAML, nil, nil
	}
	nodes, ok := topology["nodes"].(map[string]any)
	if !ok || nodes == nil || len(nodes) == 0 {
		return containerlabYAML, nil, nil
	}

	// NOTE: This function also performs Skyforge-specific compatibility tweaks for running
	// containerlab nodes as Kubernetes pods (clabernetes). These should apply even when no
	// node name rewriting is needed.
	//
	// Expose management ports on per-node ClusterIP services so in-cluster consumers (Forward
	// collector, Skyforge terminal) can reliably reach nodes cross-node via stable DNS names.
	// We use full port definitions (src:dst[/proto]) to avoid clabernetes port parsing quirks
	// with "bare" port values.
	{
		defaults, _ := topology["defaults"].(map[string]any)
		if defaults == nil {
			defaults = map[string]any{}
			topology["defaults"] = defaults
		}

		var ports []any
		existing := map[string]bool{}

		addExisting := func(raw string) {
			raw = strings.TrimSpace(raw)
			if raw == "" {
				return
			}
			// normalize for de-duping
			key := strings.ToUpper(raw)
			existing[key] = true
		}

		switch cur := defaults["ports"].(type) {
		case []any:
			ports = append(ports, cur...)
			for _, v := range cur {
				addExisting(fmt.Sprintf("%v", v))
			}
		case []string:
			for _, v := range cur {
				ports = append(ports, v)
				addExisting(v)
			}
		case nil:
			// nothing
		default:
			// Unexpected shape; preserve it by appending string form, then normalize.
			ports = append(ports, fmt.Sprintf("%v", cur))
			addExisting(fmt.Sprintf("%v", cur))
		}

		ensurePort := func(def string) {
			def = strings.TrimSpace(def)
			if def == "" {
				return
			}
			key := strings.ToUpper(def)
			if existing[key] {
				return
			}
			existing[key] = true
			ports = append(ports, def)
		}

		ensurePort("22:22/tcp")
		ensurePort("443:443/tcp")
		ensurePort("161:161/udp")

		defaults["ports"] = ports
		topology["defaults"] = defaults
	}

	vrnetlabPortDefs := []string{
		"22:22/tcp",
		"80:80/tcp",
		"443:443/tcp",
		"830:830/tcp",
		"57400:57400/tcp",
		"161:161/udp",
	}

	// Create deterministic mapping and avoid collisions.
	oldNames := make([]string, 0, len(nodes))
	for name := range nodes {
		oldNames = append(oldNames, name)
	}
	sort.Strings(oldNames)

	mapping := map[string]string{}
	used := map[string]bool{}
	for _, old := range oldNames {
		newName := sanitizeDNS1035Label(old)
		base := newName
		for i := 2; used[newName]; i++ {
			suffix := fmt.Sprintf("-%d", i)
			max := 63 - len(suffix)
			if max < 1 {
				newName = "n" + suffix
			} else if len(base) > max {
				newName = base[:max] + suffix
			} else {
				newName = base + suffix
			}
		}
		used[newName] = true
		if newName != old {
			mapping[old] = newName
		}
	}

	newNodes := map[string]any{}
	for old, cfg := range nodes {
		newName := old
		if v, ok := mapping[old]; ok {
			newName = v
		}
		cfgMap, cfgIsMap := cfg.(map[string]any)
		if cfgIsMap {
			// containerlab YAMLs often set per-node `runtime: docker` (even when the topology
			// is intended to be portable). In clabernetes native mode, these nodes run as
			// Kubernetes pods via containerd, and this field is ignored. Remove it to avoid
			// operator confusion ("are we using Docker-in-Docker?").
			if _, ok := cfgMap["runtime"]; ok {
				delete(cfgMap, "runtime")
			}

			// Ensure cEOS (systemd) nodes can run reliably in Kubernetes.
			//
			// The cEOS container expects a writable cgroup mount and access to host kernel modules.
			// With Docker, containerlab handles this; in Kubernetes native mode we must add the binds
			// explicitly so the clabernetes controller can translate them into volume mounts.
			kind := strings.ToLower(strings.TrimSpace(fmt.Sprintf("%v", cfgMap["kind"])))
			image := strings.ToLower(strings.TrimSpace(fmt.Sprintf("%v", cfgMap["image"])))
			isCEOS := kind == "ceos" || strings.Contains(image, "/ceos:") || strings.HasSuffix(image, ":ceos")
			if isCEOS {
				bindsAny, _ := cfgMap["binds"]
				var binds []any
				if cur, ok := bindsAny.([]any); ok && len(cur) > 0 {
					binds = cur
				}
				ensureBind := func(bind string) {
					bind = strings.TrimSpace(bind)
					if bind == "" {
						return
					}
					for _, bAny := range binds {
						if strings.TrimSpace(fmt.Sprintf("%v", bAny)) == bind {
							return
						}
					}
					binds = append(binds, bind)
				}
				ensureBind("/sys/fs/cgroup:/sys/fs/cgroup:rw")
				ensureBind("/lib/modules:/lib/modules:ro")
				if len(binds) > 0 {
					cfgMap["binds"] = binds
				}

				// systemd refuses to run when it believes it's running in a chroot. In Kubernetes,
				// this can happen due to how the container filesystem is mounted. The cEOS node
				// image uses systemd as PID 1, so set the recommended env vars.
				env := map[string]any{}
				switch cur := cfgMap["env"].(type) {
				case map[string]any:
					env = cur
				case map[any]any:
					for k, v := range cur {
						key := strings.TrimSpace(fmt.Sprintf("%v", k))
						if key != "" {
							env[key] = v
						}
					}
				}
				if _, ok := env["SYSTEMD_IGNORE_CHROOT"]; !ok {
					env["SYSTEMD_IGNORE_CHROOT"] = "1"
				}
				if _, ok := env["container"]; !ok {
					env["container"] = "docker"
				}
				if len(env) > 0 {
					cfgMap["env"] = env
				}
			}
		}
		// Also rewrite any node_files binds that include the original node directory name.
		if cfgIsMap {
			if bindsAny, ok := cfgMap["binds"]; ok {
				if bindsList, ok := bindsAny.([]any); ok && len(bindsList) > 0 {
					out := make([]any, 0, len(bindsList))
					for _, bAny := range bindsList {
						bind := strings.TrimSpace(fmt.Sprintf("%v", bAny))
						if bind == "" {
							continue
						}
						parts := strings.SplitN(bind, ":", 2)
						if len(parts) != 2 {
							out = append(out, bind)
							continue
						}
						hostPath := strings.TrimPrefix(strings.TrimSpace(parts[0]), "./")
						if after, ok0 := strings.CutPrefix(hostPath, "node_files/"); ok0 {
							rest := after
							seg := strings.SplitN(rest, "/", 2)
							if len(seg) >= 1 {
								if mapped, ok := mapping[seg[0]]; ok {
									seg[0] = mapped
									rest = strings.Join(seg, "/")
									hostPath = "node_files/" + rest
								}
							}
						}
						out = append(out, hostPath+":"+parts[1])
					}
					cfgMap["binds"] = out
					cfg = cfgMap
				}
			}

			// Ensure vrnetlab nodes expose a full set of management ports via per-node services.
			// This keeps Skyforge/Forward connectivity stable when pods are rescheduled.
			kindLower := strings.ToLower(strings.TrimSpace(fmt.Sprintf("%v", cfgMap["kind"])))
			imageLower := strings.ToLower(strings.TrimSpace(fmt.Sprintf("%v", cfgMap["image"])))
			isVrnetlab := strings.Contains(imageLower, "vrnetlab/") || strings.Contains(imageLower, "/vrnetlab/")
			isVrnetlab = isVrnetlab || strings.HasPrefix(kindLower, "vr-") || strings.HasPrefix(kindLower, "cisco_") || strings.HasPrefix(kindLower, "juniper_") || strings.HasPrefix(kindLower, "nokia_")
			if isVrnetlab {
				var nodePorts []any
				nodeExisting := map[string]bool{}
				addExistingPort := func(raw string) {
					raw = strings.TrimSpace(raw)
					if raw == "" {
						return
					}
					nodeExisting[strings.ToUpper(raw)] = true
				}
				switch cur := cfgMap["ports"].(type) {
				case []any:
					nodePorts = append(nodePorts, cur...)
					for _, v := range cur {
						addExistingPort(fmt.Sprintf("%v", v))
					}
				case []string:
					for _, v := range cur {
						nodePorts = append(nodePorts, v)
						addExistingPort(v)
					}
				case nil:
					// nothing
				default:
					nodePorts = append(nodePorts, fmt.Sprintf("%v", cur))
					addExistingPort(fmt.Sprintf("%v", cur))
				}
				ensureNodePort := func(def string) {
					def = strings.TrimSpace(def)
					if def == "" {
						return
					}
					key := strings.ToUpper(def)
					if nodeExisting[key] {
						return
					}
					nodeExisting[key] = true
					nodePorts = append(nodePorts, def)
				}
				for _, def := range vrnetlabPortDefs {
					ensureNodePort(def)
				}
				cfgMap["ports"] = nodePorts
			}
		}
		newNodes[newName] = cfg
	}
	topology["nodes"] = newNodes

	// Rewrite link endpoints (e.g. "L1:eth1") to the sanitized node names.
	if linksAny, ok := topology["links"]; ok {
		if links, ok := linksAny.([]any); ok {
			for i, linkAny := range links {
				link, ok := linkAny.(map[string]any)
				if !ok || link == nil {
					continue
				}
				endpointsAny, ok := link["endpoints"]
				if !ok {
					continue
				}
				eps, ok := endpointsAny.([]any)
				if !ok || len(eps) == 0 {
					continue
				}
				out := make([]any, 0, len(eps))
				for _, epAny := range eps {
					ep := strings.TrimSpace(fmt.Sprintf("%v", epAny))
					if ep == "" || strings.HasPrefix(ep, "host:") {
						out = append(out, epAny)
						continue
					}
					parts := strings.SplitN(ep, ":", 2)
					if len(parts) != 2 {
						out = append(out, epAny)
						continue
					}
					if mapped, ok := mapping[parts[0]]; ok {
						ep = mapped + ":" + parts[1]
					}
					out = append(out, ep)
				}
				link["endpoints"] = out
				links[i] = link
			}
			topology["links"] = links
		}
	}

	doc["topology"] = topology

	out, err := yaml.Marshal(doc)
	if err != nil {
		return "", nil, fmt.Errorf("failed to encode containerlab yaml: %w", err)
	}
	return string(out), mapping, nil
}

func containerlabTopologyHasKind(containerlabYAML, kind string) bool {
	containerlabYAML = strings.TrimSpace(containerlabYAML)
	kind = strings.ToLower(strings.TrimSpace(kind))
	if containerlabYAML == "" || kind == "" {
		return false
	}
	var doc map[string]any
	if err := yaml.Unmarshal([]byte(containerlabYAML), &doc); err != nil || doc == nil {
		return false
	}
	topology, ok := doc["topology"].(map[string]any)
	if !ok || topology == nil {
		return false
	}
	nodes, ok := topology["nodes"].(map[string]any)
	if !ok || nodes == nil || len(nodes) == 0 {
		return false
	}
	for _, cfg := range nodes {
		cfgMap, ok := cfg.(map[string]any)
		if !ok || cfgMap == nil {
			continue
		}
		nodeKind := strings.ToLower(strings.TrimSpace(fmt.Sprintf("%v", cfgMap["kind"])))
		if nodeKind == kind {
			return true
		}
	}
	return false
}
